---
title: "From FreEM to D'AlemBERT: a Large Corpus and a Language Model for Early Modern French"
authors:
- Simon Gabay
- admin
- Alexandre Bartz
- Alix Chagué
- Rachel Bawden
- Philippe Gambette
- Benoît Sagot
date: "2022-02-18T22:12:59Z"
doi: "10.48550/arXiv.2202.09452"

# Schedule page publish date (NOT publication's date).
publishDate: "2017-01-01T00:00:00Z"

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ["3"]

# Publication name and optional abbreviated publication name.
publication: In Computation and Language 
publication_short: In cs.CL

abstract: "Language models for historical states of language are becoming increasingly important to allow the optimal digitisation and analysis of old textual sources. Because these historical states are at the same time more complex to process and more scarce in the corpora available, specific efforts are necessary to train natural language processing (NLP) tools adapted to the data. In this paper, we present our efforts to develop NLP tools for Early Modern French (historical French from the 16$^\\text{th}$ to the 18$^\\text{th}$ centuries). We present the $\\text{FreEM}\_{\\text{max}}$ corpus of Early Modern French and D'AlemBERT, a RoBERTa-based language model trained on $\\text{FreEM}\_{\\text{max}}$ . We evaluate the usefulness of D'AlemBERT by fine-tuning it on a part-of-speech tagging task, outperforming previous work on the test set. Importantly, we find evidence for the transfer learning capacity of the language model, since its performance on lesser-resourced time periods appears to have been boosted by the more resourced ones. We release D'AlemBERT and the open-sourced subpart of the $\\text{FreEM}\_{\\text{max}}$ corpus."

# Summary. An optional shortened abstract.
summary: We present the $\\text{FreEM}\_{\\text{max}}$ corpus of Early Modern French and D'AlemBERT, a RoBERTa-based language model trained on $\\text{FreEM}\_{\\text{max}}$.

tags:
featured: true

links:
# - name: ACL Anthology
#   url: https://www.aclweb.org/anthology/2020.acl-main.156/
# - name: ACL 2020
#   url: https://acl2020.org/
- name: HAL
  url: https://hal.inria.fr/hal-03596653
- name: arXiv
  url: https://arxiv.org/abs/2202.09452
url_pdf: https://arxiv.org/abs/2202.09452.pdf
#url_code: 'https://github.com/pjox/goclassy'
#url_dataset: 'https://oscar-corpus.com'
#url_poster: '#'
#url_project: ''
#url_slides: '/files/CMLC_7_slides.pdf'
#url_source: '#'
#url_video: '#'

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
image:
 caption: 'Image credit: [**Alix Chagué**](https://alix-tz.github.io/en/index.html)'
 focal_point: ""
 preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects:

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides:
---
